## Resources about variational autoencoders

## Original Research Paper with VAEs
Original paper by Kingma and Welling introducing the method.\
[Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114)

## YT series
### KL divergence
Kullbackâ€“Leibler divergence is a measure of how one probability distribution is different from a second.\
Used in VAEs to measure the difference between the learned distribution and the true distribution.\
[KL divergence explained](https://www.youtube.com/watch?v=9_eZHt2qJs4)

### Evidence Lower Bound (ELBO)
Lower bound on the log likelihood of the data, used in VAEs.\
[ELBO](https://www.youtube.com/watch?v=IXsA5Rpp25w)

### Variational Autoencoders
[Variational Autoencoders](https://www.youtube.com/watch?v=h9kWaQQloPk)

### Reparametrization trick
Allows to backpropagate in the training of VAEs.\
[Reparametrization trick](https://www.youtube.com/watch?v=nKM9875PVtU)


### Articles
A general article about VAEs by Matthew N. Bernstein.\
[Variational Autoencoders](https://mbernste.github.io/posts/vae/)